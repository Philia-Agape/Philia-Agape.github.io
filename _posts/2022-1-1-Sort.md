---
Title: Thoughts on Sorting
---
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
    
Some thoughts on sorting, of course, it's related to time and space complexity: Less is More ;)

Given an array of N number, what's the most natural way of ordering them? It's to compare them one another, and then it's Bubble sort, with 
$$ \binom{N}{x} $$ comparison, which is actually the upper bound for sorting problem, since ordered pair is transitive, namely if $$ a \geq b$$ and $$ b \geq c$$ 
then $$ a \geq c$$. Bubble sort is classical, natural but definitely can be optimized! 

```cpp
void Bubble sort(int array[], int n){
   int temp = 0;
   for(int i=0; i<n-1; ++i){ 
      //one i-loop, find maximum!
      //i.e. the last position is correct
      for(int j=0; j<n-1-i; ++j){
         if(array[j] > array[j+1]){
            temp = array[j];
            array[j] = array[i];
            array[i] = array[j];
         }
      }  
   }
   return;
}
```
Bubble sort has time complexity $$ O(N^2)$$.

What did we make progress on Quick Sort then? Actually we utilize one loop search to the most, the comparison of one element with the other N-1 times provides
the info of the correct position of the element itself, so we can divide the array into two parts with the correct position we found as the cutting point, 
and repeat the process separately.

```cpp
void quicksort(int (&array) [n], int l, int r){
   int temp = array[l], left = l, right = r;
   //This is the value we need help to find correct position this time!
   
   // r-l < 1, size <=2 , satisfy recursion condition!   
   if(right-left<=1){
   
      // this may lead to core dump, wrong example -> if(array[left] > array[right]){    
      
      if(array[l] > array[r] && 0<=l && l<n && 0<=r && r<n && l<=r){
      
         //ensure l & r are not out of boundary (may happen by call of quicksort) 
         //and l<=r is the necessary condition to replace two elements!
      
         array[l] = array[r];
         array[r] = temp;
      }
      return;
   }
   
   
   
   while(left < right){ 
      
      
      
      //Q1: why not left <= right?
      //b.c. we need to break the inside while loop if left==right, and thus outside break, 
      //and assign temp to array[left], i.e. array[right], since left==right
      
      //array[left] is to be replaced by a value greater than temp
      
      //Q2: why add condition left<=right? b.c. we need to ensure in this while loop
      //the first while loop do not ensure the process here
      //i.e. it did not check everytime, it only check once the while finish
      
      while(left < right && temp <= array[right--]){
         //r--;
      }
      array[left] = array[right];
      
      //array[right] is to be replaced a value smaller than temp
      while(left <= right && temp >= array[left++]){
         //l++;
      }
      
      //array[right] is to be replaced
      array[right] = array[left];
   }
   array[right] = temp;
   
   quicksort(array,l,left-1);
   quicksort(array,left+1,r);
   
   //Below are wrong:
   //quicksort(array,0,r-1);
   //quicksort(array,r+1,n-1);
   
   return;
}
```
The idea here is, we iterate through the array from the right side (from reverse beginning), and if there's an element smaller than the first element, we 
replace the array at left index by this value, and iterate from left to find an element replace the array at right index, or until both right and left meet 
at the same index, by doing so we divide the array into two parts, and we repeat the above method until the size of interval is less than or equal to 2, for
later case, we need to realize the fact that if $$b<a$$ and $$c<a$$, we can not ensure $$ b<c$$ or $$c<b$$! That's why we need to check even if the interval 
size of array is only two. 

We need to pay attention to the while loop indeed, because it only checks the first time we enter this while loop and everytime we finish the while loop. 
Therefore, we **MUST ensure $$ first < last $$ both inside and outside the while$$** Because inside the while we do not make any cursor movement, i.e. plus 
first or decrease last if 

An important trick is, we don't make any change if the comparison value is equal, since assigning value would contribute time complexity, consider the example where all values are equal but a very large size array; Also, we compare value by $$l++$$, which is actually comparing with $$l+1$$, thus reducing compare with itself.   

One interesting thing is, if we would like to know the maximum or minimum value in the given array of size N, we need to compare N-1 times, but if we need to 
know the value of some position in the middle, it's hard to say whether repeat the process or simply quick sort then check the position: if we are interested 
in location with distance k from the beginning or end as minimum, i.e. $$ k = min(dis(0,pos),dis(pos,n-1)) = min(pos,n-1-pos) $$. It's a comparison between 
$$ nlogn $$, and $$ \frac{(k+1)((n-1)+(n-1-k))}{2} = \frac{(k+1)(2n-2-k)}{2}$$, which is the complexity of quicksort and k-times maximum or minimum finding.

Check [Pass by int array](https://stackoverflow.com/questions/8767166/passing-a-2d-array-to-a-c-function) as a reminder.

P.S. Imagine we were living in a period of no computer, then sorting algorithm was definitely not valuable, but we could still derive these complexity analysis, of course, with no practical use, as the only way to fight with infinity is to do a little more as always, this will be my theme for 2022 ;)

