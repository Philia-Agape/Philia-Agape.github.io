---
Title: Thoughts on Sorting
---
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
    
Some thoughts on sorting, of course, it's related to time and space complexity: Less is More ;)

Given an array of N number, what's the most natural way of ordering them? It's to compare them one another, and then it's Bubble sort, with 
$$ \binom{N}{x} $$ comparison, which is actually the upper bound for sorting problem, since ordered pair is transitive, namely if $$ a \geq b$$ and $$ b \geq c$$ 
then $$ a \geq c$$. Bubble sort is classical, natural but definitely can be optimized! 

```cpp
void Bubble sort(int array[], int n){
   int temp = 0;
   for(int i=0; i<n-1; ++i){ 
      //one i-loop, find maximum!
      //i.e. the last position is correct
      for(int j=0; j<n-1-i; ++j){
         if(array[j] > array[j+1]){
            temp = array[j];
            array[j] = array[i];
            array[i] = array[j];
         }
      }  
   }
   return;
}
```
Bubble sort has time complexity $$ O(N^2)$$.

What did we make progress on Quick Sort then? Actually we utilize one loop search to the most, the comparison of one element with the other N-1 times provides
the info of the correct position of the element itself, so we can divide the array into two parts with the correct position we found as the cutting point, 
and repeat the process separately.

```cpp
void quicksort(int (&array) [n], int l, int r){
   int temp = array[l];
   //This is the value we need help to find correct position this time!
   
   // r-l < 1, recursion condition   
   if(r-l<=1){
      if(array[l] < array[r]){
         array[l] = array[r];
         array[r] = temp;
      }
      return;
   }
   
   //why not l<=r? Think of it!
   
   while(l<r){ 
      //array[l] is to be replaced by a value greater than temp
      while(l <= r && temp <= array[r--]){
         //r--;
      }
      array[l] = array[r];
      
      //array[r] is to be replaced a value smaller than temp
      while(l <= r && temp >= array[l++]){
         //l++;
      }
      //array[r] is to be replaced
      array[r] = array[l];
   }
   array[r] = temp;
   quicksort(array,0,r-1);
   quicksort(array,r+1,n-1);
   return;
}
```
The idea here is, we iterate through the array from the right side (from reverse beginning), and if there's an element smaller than the first element, we 
replace the array at left index by this value, and iterate from left to find an element replace the array at right index, or until both right and left meet 
at the same index, by doing so we divide the array into two parts, and we repeat the above method until the size of interval is less than or equal to 2, for
later case, we need to realize the fact that if $$b<a$$ and $$c<a$$, we can not ensure $$ b<c$$ or $$c<b$$! That's why we need to check even if the interval 
size of array is only two. 

An important trick is, we don't make any change if the comparison value is equal, since assigning value would contribute time complexity, consider the example where all values are equal but a very large size array; Also, we compare value by $$l++$$, which is actually comparing with $$l+1$$, thus reducing compare with itself.   

One interesting thing is, if we would like to know the maximum or minimum value in the given array of size N, we need to compare N-1 times, but if we need to 
know the value of some position in the middle, it's hard to say whether repeat the process or simply quick sort then check the position: if we are interested 
in location with distance k from the beginning or end as minimum, i.e. $$ k = min(dis(0,pos),dis(pos,n-1)) = min(pos,n-1-pos) $$. It's a comparison between 
$$ nlogn $$, and $$ \frac{(k+1)((n-1)+(n-1-k))}{2} = \frac{(k+1)(2n-2-k)}{2}$$, which is the complexity of quicksort and k-times maximum or minimum finding.

P.S. Imagine we were living in a period of no computer, then sorting algorithm was definitely not valuable, but we could still derive these complexity analysis, of course, with no practical use, as the only way to fight with infinity is to do a little more as always, this will be my theme for 2022 ;)

